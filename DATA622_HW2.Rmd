---
title: "DATA622_HW2"
author: "IR"
date: "3/12/2021"
output: 
 html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: flatly
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r comment=FALSE, message=FALSE}
library(palmerpenguins)
library(tidyr)
library(dplyr)
library(ggplot2)
library(mlbench)
library(MASS)
library(pROC)
library(stringr)
library(ggplot2)
library(caret)
library(palmerpenguins)
```


Generative Models (100 points)

We will be working with the Penguin dataset again as we did for Homework #1. Please use “Species” as your target variable. For this assignment, you may want to drop/ignore the variable “year”. Using the target variable, Species, please conduct:

## a. You want to evaluate all the ‘features’ or dependent variables and see what should be in your model. 
```{r}
glimpse(penguins)
```
```{r}
#Omit NA's and Remove year as indicated
newpenguin <-na.omit(penguins)
df <-subset(newpenguin, select = -c(year))
glimpse(df)
```
## b. Just a suggestion: You might want to consider exploring feature Plot on the caret package. Basically, you look at each of the features/dependent variables and see how they are different based on species. Simply eye-balling this might give you an idea about which would be strong ‘classifiers’ (aka predictors).
```{r}
featurePlot(x = df[, 2:7], 
            y = df$species, 
            plot = "pairs",
 strip=strip.custom(par.strip.text=list(cex=.7)),
            scales = list(x = list(relation="free"), 
                          y = list(relation="free")))
```

# 1 Linear Discriminant Analysis (30 points):

## a. Fit your LDA model using whatever predictor variables you deem appropriate. Feel free to split the data into training and test sets before fitting the model.


```{r}
# Split the data into training (80%) and test set (20%) 
set.seed(123) 
training.individuals <- df$species %>% createDataPartition(p = 0.8, list = FALSE) 
train.data <- df[training.individuals, ] 
test.data <- df[-training.individuals, ] 

# Estimate preprocessing parameters 
preproc.parameter <- train.data %>% 
preProcess(method = c("center", "scale")) 

# Transform the data using the estimated parameters 
train.transform <- preproc.parameter %>% predict(train.data) 
test.transform <- preproc.parameter %>% predict(test.data) 

# Fit the model 
model <- lda(species~., data = train.transform) 

# Make predictions 
predictions <- model %>% predict(test.transform) 

model <- lda(species~., data = train.transform) 
model

```

```{r}
# Graphical plotting of the output 

library(ggplot2) 
library(MASS) 
library(mvtnorm) 

# Variance Covariance matrix for random bivariate gaussian sample 
var_covar = matrix(data = c(1.5, 0.4, 0.4, 1.5), nrow = 2) 

# Random bivariate Gaussian samples for class +1 
Xplus1 <- rmvnorm(400, mean = c(5, 5), sigma = var_covar) 

# Random bivariate Gaussian samples for class -1 
Xminus1 <- rmvnorm(600, mean = c(3, 3), sigma = var_covar) 

# Samples for the dependent variable 
Y_samples <- c(rep(1, 400), rep(-1, 600)) 

# Combining the independent and dependent variables into a dataframe 
dataset <- as.data.frame(cbind(rbind(Xplus1, Xminus1), Y_samples)) 
colnames(dataset) <- c("X1", "X2", "Y") 
dataset$Y <- as.character(dataset$Y) 

# Plot the above samples and color by class labels 
ggplot(data = dataset) + geom_point(aes(X1, X2, color = Y)) 

```

## b. Look at the fit statistics/ accuracy rates.
```{r}
#model %>%metrics(truth = species, estimate = prediction)
#confusionMatrix(df$species,df$species)
# Model accuracy 
accuracy <-mean(predictions$class==test.transform$species) 
#accuracy
```


# 2 Quadratic Discriminant Analysis (30 points)

## a. Fit your QDA model using whatever predictor variables you deem appropriate. Feel free to split the data into training and test sets before fitting the model.

## b. Look at the fit statistics/ accuracy rates.

# 3 Naïve Bayes (30 points)

## a. Fit your NB model using whatever predictor variables you deem appropriate. Feel free to split the data into training and test sets before fitting the model.

## b. Look at the fit statistics/ accuracy rates.

# 4 Comment on the models fits/strength/weakness/accuracy for all these three models that you worked with. (10 points)

# References
https://www.geeksforgeeks.org/linear-discriminant-analysis-in-r-programming/
